{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0dafaf-d568-44ad-b271-b46cdab8d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d13b63-1c3a-4eac-8a14-213e2514bcd8",
   "metadata": {},
   "source": [
    "## trianing data 전처리\n",
    "- 데이터의 오류 유형에 관한 질문과 해당 질문에 대한 답변, 답변이 포함된 텍스트 위치를 학습\n",
    "\n",
    "디렉토리 정보\n",
    "- input : '../data/original/training/'\n",
    "- output : '../data/training/'\n",
    "\n",
    "csv파일 명칭 정보\n",
    "- training_machine_fact.csv : TL_기계요약문_사실전달형_corrected_type1 ~ TL_기계요약문_사실전달형_corrected_type6\n",
    "- training_machine_opinion.csv : TL_기계요약문_의견제시형_corrected_type1 ~ TL_기계요약문_의견제시형_corrected_type6\n",
    "- training_machine_free.csv : TL_기계요약문_자유형_corrected_type1 ~ TL_기계요약문_자유형_corrected_type6\n",
    "- training_human_fact.csv : TL_사람요약문_사실전달형_corrected_type1 ~ TL_사람요약문_사실전달형_corrected_type6\n",
    "- training_human_opinion.csv : TL_사람요약문_의견제시형_corrected_type1 ~ TL_사람요약문_의견제시형_corrected_type6\n",
    "- training_human_free.csv : TL_사람요약문_자유형_corrected_type1 ~ TL_사람요약문_자유형_corrected_type6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7d5008-3a83-48ef-9ae6-2cee1a281443",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_path = '../data_original/training/'\n",
    "base_output_dir_path = './data/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4585e89-cba9-4558-9ed2-f8a3332be4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_type_question(type):\n",
    "    if type==1:\n",
    "        return '한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?'\n",
    "    elif type==2:\n",
    "        return '단어 선택 오류가 발생한 부분은?'\n",
    "    elif type==3:\n",
    "        return '비문이 발생한 부분은?'\n",
    "    elif type==4:\n",
    "        return '미완성 또는 불완전한 문장이 발생한 부분은?'\n",
    "    elif type==5:\n",
    "        return '키워드 또는 중요 내용 오류가 발생한 부분은?'\n",
    "    elif type==6:\n",
    "        return '유사한 내용이 반복되는 오류가 발생한 부분은?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2404ff-df17-487e-bde0-66b3bcc55911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (3627, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                             answers  \\\n",
      "0          {'text': ['180억원'], 'answer_start': [34]}   \n",
      "1         {'text': ['발산했다 .'], 'answer_start': [76]}   \n",
      "2  {'text': ['대상학생들에게  자가운동'], 'answer_start': [87]}   \n",
      "3            {'text': ['승차후'], 'answer_start': [58]}   \n",
      "4          {'text': ['배터리사업'], 'answer_start': [71]}   \n",
      "\n",
      "                                             context  \n",
      "0  [original]제이테크놀로지(옛 마제스타)가 카지노 자회사 매각을 완료해 재무건...  \n",
      "1  [original]글로벌 뷰티 브랜드 랑콤이 패션 매거진 <마리끌레르>와 함께한 배...  \n",
      "2  [original]법동초 시작관내 초 순회 진단. 대덕구가 지난 30일 우송대학교 ...  \n",
      "3  [original]경기파주시 최종환시장은 지난 4일 신설 마을버스 운행 첫날 시민들...  \n",
      "4  [original]배터리 셀을 든 최태원(가운데) 회장이 김진영 배터리생산기술본부장...  \n",
      "데이터가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# TL_사람요약문_사실전달형_corrected_type1 ~ TL_사람요약문_사실전달형_corrected_type6\n",
    "\n",
    "# 데이터프레임을 합칠 때 사용할 리스트\n",
    "data_frames = []\n",
    "\n",
    "# 각 타입별 폴더를 반복 처리\n",
    "for type_num in range(1, 7):\n",
    "    human_type_data_path = base_dir_path + f'TL_사람요약문_사실전달형_corrected_type{type_num}'\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 가져오고, '.json' 확장자를 가진 파일만 필터링\n",
    "    json_files = [file for file in os.listdir(human_type_data_path) if file.endswith('.json')]\n",
    "\n",
    "    # 전체 파일 순회\n",
    "    for index, filename in enumerate(json_files):\n",
    "        json_path = os.path.join(human_type_data_path, filename)\n",
    "        with open(json_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            id = data['annotation']['original_summary']['human_abstractive_summary']['author']['id']\n",
    "            \n",
    "            original_text = data['original_text']\n",
    "            corrected_type = type_num\n",
    "            summary_text = data['annotation']['original_summary']['human_abstractive_summary']['text']\n",
    "            question = error_type_question(corrected_type)\n",
    "\n",
    "            corrected_summary = data['annotation']['corrected_summary']\n",
    "            corrected_text = corrected_summary[f'corrected_type{type_num}']['errors'][0]['sub']\n",
    "            error_begin = corrected_summary[f'corrected_type{type_num}']['errors'][0]['begin']\n",
    "            answers = {'text': [corrected_text], 'answer_start': [error_begin]}\n",
    "            \n",
    "            data_list.append({\n",
    "                'id' : id,\n",
    "                'original': original_text,\n",
    "                'summary': summary_text,\n",
    "                # 'label': corrected_type,\n",
    "                'question' : question,\n",
    "                'answers' : answers\n",
    "            })\n",
    "\n",
    "        # 각 파일 처리 후 DataFrame 생성 및 'text' 열 추가\n",
    "        type_data_df = pd.DataFrame(data_list)\n",
    "        type_data_df['context'] = '[original]' + type_data_df['original'] + '[/original][summary]' + type_data_df['summary'] + '[/summary]'\n",
    "        type_data_df.drop(columns=['original', 'summary'], inplace=True)\n",
    "\n",
    "    # 타입별 데이터프레임을 합친다\n",
    "    data_frames.append(type_data_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 병합\n",
    "data_df_training_human_fact = pd.concat(data_frames, ignore_index=True)\n",
    "print('shape: ', data_df_training_human_fact.shape)\n",
    "print(data_df_training_human_fact.head())\n",
    "\n",
    "# # csv 파일 경로 설정\n",
    "csv_path = base_output_dir_path + 'training_human_fact.csv'\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "data_df_training_human_fact.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'데이터가 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c7accf-8aff-4368-9227-578a9f72d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (3412, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                        answers  \\\n",
      "0    {'text': ['바로잡는것이'], 'answer_start': [99]}   \n",
      "1      {'text': ['받지못한'], 'answer_start': [64]}   \n",
      "2    {'text': ['할것이다.'], 'answer_start': [162]}   \n",
      "3  {'text': ['대해  적극적인'], 'answer_start': [98]}   \n",
      "4    {'text': ['응시해야한다'], 'answer_start': [97]}   \n",
      "\n",
      "                                             context  \n",
      "0  [original]고용노동부가 최근 국무회의에서 발표한 2011~2020 중장기 인...  \n",
      "1  [original]지난 3월 20일 서울시의회에서는 촛불혁명으로 어렵사리 진전시켜놓...  \n",
      "2  [original]일본의 경제보복 사태가 여전히 살얼음판이다. 일본이 금수 초지한 ...  \n",
      "3  [original]부산시가 해수담수화 시설 산업용수의 수요처로 예상했던 울산 온산미...  \n",
      "4  [original]북한 비핵화를 위한 하노이 선언이 무산됐다. 전 세계의 뜨거운 관...  \n",
      "데이터가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# TL_사람요약문_의견제시형_corrected_type1 ~ TL_사람요약문_의견제시형_corrected_type6\n",
    "\n",
    "# 데이터프레임을 합칠 때 사용할 리스트\n",
    "data_frames = []\n",
    "# id = 1\n",
    "\n",
    "# 각 타입별 폴더를 반복 처리\n",
    "for type_num in range(1, 7):\n",
    "    human_type_data_path = base_dir_path + f'TL_사람요약문_의견제시형_corrected_type{type_num}'\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 가져오고, '.json' 확장자를 가진 파일만 필터링\n",
    "    json_files = [file for file in os.listdir(human_type_data_path) if file.endswith('.json')]\n",
    "\n",
    "    # 전체 파일 순회\n",
    "    for index, filename in enumerate(json_files):\n",
    "        json_path = os.path.join(human_type_data_path, filename)\n",
    "        with open(json_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            id = data['annotation']['original_summary']['human_abstractive_summary']['author']['id']\n",
    "            original_text = data['original_text']\n",
    "            corrected_type = type_num\n",
    "            summary_text = data['annotation']['original_summary']['human_abstractive_summary']['text']\n",
    "            question = error_type_question(corrected_type)\n",
    "\n",
    "            corrected_summary = data['annotation']['corrected_summary']\n",
    "            corrected_text = corrected_summary[f'corrected_type{type_num}']['errors'][0]['sub']\n",
    "            error_begin = corrected_summary[f'corrected_type{type_num}']['errors'][0]['begin']\n",
    "            answers = {'text': [corrected_text], 'answer_start': [error_begin]}\n",
    "            \n",
    "            data_list.append({\n",
    "                'id' : id,\n",
    "                'original': original_text,\n",
    "                'summary': summary_text,\n",
    "                # 'label': corrected_type,\n",
    "                'question' : question,\n",
    "                'answers' : answers\n",
    "            })\n",
    "            # id = id+1\n",
    "\n",
    "        # 각 파일 처리 후 DataFrame 생성 및 'text' 열 추가\n",
    "        type_data_df = pd.DataFrame(data_list)\n",
    "        type_data_df['context'] = '[original]' + type_data_df['original'] + '[/original][summary]' + type_data_df['summary'] + '[/summary]'\n",
    "        type_data_df.drop(columns=['original', 'summary'], inplace=True)\n",
    "\n",
    "    # 타입별 데이터프레임을 합친다\n",
    "    data_frames.append(type_data_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 병합\n",
    "data_df_training_human_opinion = pd.concat(data_frames, ignore_index=True)\n",
    "print('shape: ', data_df_training_human_opinion.shape)\n",
    "print(data_df_training_human_opinion.head())\n",
    "\n",
    "# # csv 파일 경로 설정\n",
    "csv_path = base_output_dir_path + 'training_human_opinion.csv'\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "data_df_training_human_opinion.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'데이터가 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec61ce4-3020-4841-89be-0baf7db91501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (1871, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                             answers  \\\n",
      "0  {'text': ['법행위의 피해자가 무직자인 경우에 그 소극적 손해의 산정기준은 ...   \n",
      "1  {'text': ['개정 법률에 규정된 부칙 규정은 원래 법률의 개정에 따른 당해 ...   \n",
      "2  {'text': ['상표등록취소심판청구 계속 중 상표권자의 상표권 포기로 상표등록이...   \n",
      "3  {'text': ['주주명단에는 실주소지 기재에 대한 근거가 주주명단에는 실주소지 ...   \n",
      "4  {'text': ['취득을 고유업무에 직접 사용하다가 1년 이내에 매각한 경우 구 ...   \n",
      "\n",
      "                                             context  \n",
      "0  [original]가. 불법행위의 피해자가 입은 소극적 손해를 산정함에 있어 노동능...  \n",
      "1  [original]1 지방세법 제109조 제3항 본문은 토지구획정리사업법에 의한 토...  \n",
      "2  [original]가. 상표법 제43조 제1항 제1호에 의한 상표등록취소심판청구는 ...  \n",
      "3  [original]가. 제2차 납세의무자에 해당하는 과점주주인 여부는 과세처분을 한...  \n",
      "4  [original]가. 면제된 취득세, 등록세의 추징에 관한 규정인 구 지방세법(1...  \n",
      "데이터가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# TL_사람요약문_자유형_corrected_type1 ~ TL_사람요약문_자유형_corrected_type6\n",
    "\n",
    "# 데이터프레임을 합칠 때 사용할 리스트\n",
    "data_frames = []\n",
    "# id = 1\n",
    "\n",
    "# 각 타입별 폴더를 반복 처리\n",
    "for type_num in range(1, 7):\n",
    "    human_type_data_path = base_dir_path + f'TL_사람요약문_자유형_corrected_type{type_num}'\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 가져오고, '.json' 확장자를 가진 파일만 필터링\n",
    "    json_files = [file for file in os.listdir(human_type_data_path) if file.endswith('.json')]\n",
    "\n",
    "    # 전체 파일 순회\n",
    "    for index, filename in enumerate(json_files):\n",
    "        json_path = os.path.join(human_type_data_path, filename)\n",
    "        with open(json_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            id = data['annotation']['original_summary']['human_abstractive_summary']['author']['id']\n",
    "            original_text = data['original_text']\n",
    "            corrected_type = type_num\n",
    "            summary_text = data['annotation']['original_summary']['human_abstractive_summary']['text']\n",
    "            question = error_type_question(corrected_type)\n",
    "\n",
    "            corrected_summary = data['annotation']['corrected_summary']\n",
    "            corrected_text = corrected_summary[f'corrected_type{type_num}']['text']\n",
    "            error_begin = corrected_summary[f'corrected_type{type_num}']['errors'][0]['begin']\n",
    "            answers = {'text': [corrected_text], 'answer_start': [error_begin]}\n",
    "            \n",
    "            data_list.append({\n",
    "                'id' : id,\n",
    "                'original': original_text,\n",
    "                'summary': summary_text,\n",
    "                # 'label': corrected_type,\n",
    "                'question' : question,\n",
    "                'answers' : answers\n",
    "            })\n",
    "            # id = id+1\n",
    "\n",
    "        # 각 파일 처리 후 DataFrame 생성 및 'text' 열 추가\n",
    "        type_data_df = pd.DataFrame(data_list)\n",
    "        type_data_df['context'] = '[original]' + type_data_df['original'] + '[/original][summary]' + type_data_df['summary'] + '[/summary]'\n",
    "        type_data_df.drop(columns=['original', 'summary'], inplace=True)\n",
    "\n",
    "    # 타입별 데이터프레임을 합친다\n",
    "    data_frames.append(type_data_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 병합\n",
    "data_df_training_human_free = pd.concat(data_frames, ignore_index=True)\n",
    "print('shape: ', data_df_training_human_free.shape)\n",
    "print(data_df_training_human_free.head())\n",
    "\n",
    "# # csv 파일 경로 설정\n",
    "csv_path = base_output_dir_path + 'training_human_free.csv'\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "data_df_training_human_free.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'데이터가 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e5b69a9-cb8e-419d-bd8f-66079017343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합이 완료되었습니다.\n",
      "shape: (8910, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                             answers  \\\n",
      "0          {'text': ['180억원'], 'answer_start': [34]}   \n",
      "1         {'text': ['발산했다 .'], 'answer_start': [76]}   \n",
      "2  {'text': ['대상학생들에게  자가운동'], 'answer_start': [87]}   \n",
      "3            {'text': ['승차후'], 'answer_start': [58]}   \n",
      "4          {'text': ['배터리사업'], 'answer_start': [71]}   \n",
      "\n",
      "                                             context  \n",
      "0  [original]제이테크놀로지(옛 마제스타)가 카지노 자회사 매각을 완료해 재무건...  \n",
      "1  [original]글로벌 뷰티 브랜드 랑콤이 패션 매거진 <마리끌레르>와 함께한 배...  \n",
      "2  [original]법동초 시작관내 초 순회 진단. 대덕구가 지난 30일 우송대학교 ...  \n",
      "3  [original]경기파주시 최종환시장은 지난 4일 신설 마을버스 운행 첫날 시민들...  \n",
      "4  [original]배터리 셀을 든 최태원(가운데) 회장이 김진영 배터리생산기술본부장...  \n"
     ]
    }
   ],
   "source": [
    "# training 사람요약문 병합\n",
    "\n",
    "csv_paths = [\n",
    "    base_output_dir_path + 'training_human_fact.csv',\n",
    "    base_output_dir_path + 'training_human_opinion.csv',\n",
    "    base_output_dir_path + 'training_human_free.csv'\n",
    "]\n",
    "\n",
    "dataframes = [pd.read_csv(path) for path in csv_paths]\n",
    "merged_training_human_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 결과 DataFrame을 새로운 CSV 파일로 저장\n",
    "output_path = base_output_dir_path + 'training_human_data.csv'\n",
    "merged_training_human_dataframe.to_csv(output_path, index=False)\n",
    "\n",
    "print('병합이 완료되었습니다.')\n",
    "print('shape:', merged_training_human_dataframe.shape)\n",
    "print(merged_training_human_dataframe.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cda22d-e135-4f8b-ac74-107272398ab5",
   "metadata": {},
   "source": [
    "## validation data 전처리\n",
    "- 데이터의 오류 유형에 관한 질문과 해당 질문에 대한 답변, 답변이 포함된 텍스트 위치를 학습\n",
    "\n",
    "디렉토리 정보\n",
    "- input : '../data/original/validation/'\n",
    "- output : '../data/validation/'\n",
    "\n",
    "csv파일 명칭 정보\n",
    "- validation_machine_fact.csv : VL_기계요약문_사실전달형_corrected_type1 ~ VL_기계요약문_사실전달형_corrected_type6\n",
    "- validation_machine_opinion.csv : VL_기계요약문_의견제시형_corrected_type1 ~ VL_기계요약문_의견제시형_corrected_type6\n",
    "- validation_machine_free.csv : VL_기계요약문_자유형_corrected_type1 ~ VL_기계요약문_자유형_corrected_type6\n",
    "- validation_human_fact.csv : VL_사람요약문_사실전달형_corrected_type1 ~ VL_사람요약문_사실전달형_corrected_type6\n",
    "- validation_human_opinion.csv : VL_사람요약문_의견제시형_corrected_type1 ~ VL_사람요약문_의견제시형_corrected_type6\n",
    "- validation_human_free.csv : VL_사람요약문_자유형_corrected_type1 ~ VL_사람요약문_자유형_corrected_type6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f60447-79fd-42eb-ad8c-80df1ad04f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_path = '../data_original/validation/'\n",
    "base_output_dir_path = './data/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b306caf-4359-4cbe-8b07-98b9cb119274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (454, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                            answers  \\\n",
      "0          {'text': ['9시5분'], 'answer_start': [82]}   \n",
      "1          {'text': ['3배가량'], 'answer_start': [49]}   \n",
      "2  {'text': ['상승했고 ,증권업계는'], 'answer_start': [115]}   \n",
      "3    {'text': ['2억3000만원을'], 'answer_start': [105]}   \n",
      "4        {'text': ['순으로매년'], 'answer_start': [145]}   \n",
      "\n",
      "                                             context  \n",
      "0  [original]30일 코스닥 지수는 보합권에서 상승 출발했다. 미국 연방공개시장...  \n",
      "1  [original]경기도 노후 하수관이 1만㎞에 달하며 지하안전 주의보가 발령된(본...  \n",
      "2  [original]정부와 여당인 더불어민주당이 증권거래세 폐지를 본격 추진하면서 주...  \n",
      "3  [original]엄재천 올해 장학생 280명 선발2억3천만원 지급 계획,  22일...  \n",
      "4  [original]전북경찰이 해마다 업무 중 불의의 사고를 당하는 것으로 나타났다....  \n",
      "데이터가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# VL_사람요약문_사실전달형_corrected_type1 ~ VL_사람요약문_사실전달형_corrected_type6\n",
    "\n",
    "# 데이터프레임을 합칠 때 사용할 리스트\n",
    "data_frames = []\n",
    "# id = 1\n",
    "\n",
    "# 각 타입별 폴더를 반복 처리\n",
    "for type_num in range(1, 7):\n",
    "    human_type_data_path = base_dir_path + f'VL_사람요약문_사실전달형_corrected_type{type_num}'\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 가져오고, '.json' 확장자를 가진 파일만 필터링\n",
    "    json_files = [file for file in os.listdir(human_type_data_path) if file.endswith('.json')]\n",
    "\n",
    "    # 전체 파일 순회\n",
    "    for index, filename in enumerate(json_files):\n",
    "        json_path = os.path.join(human_type_data_path, filename)\n",
    "        with open(json_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            id = data['annotation']['original_summary']['human_abstractive_summary']['author']['id']\n",
    "            original_text = data['original_text']\n",
    "            corrected_type = type_num\n",
    "            summary_text = data['annotation']['original_summary']['human_abstractive_summary']['text']\n",
    "            question = error_type_question(corrected_type)\n",
    "\n",
    "            corrected_summary = data['annotation']['corrected_summary']\n",
    "            corrected_text = corrected_summary[f'corrected_type{type_num}']['errors'][0]['sub']\n",
    "            error_begin = corrected_summary[f'corrected_type{type_num}']['errors'][0]['begin']\n",
    "            answers = {'text': [corrected_text], 'answer_start': [error_begin]}\n",
    "            \n",
    "            data_list.append({\n",
    "                'id' : id,\n",
    "                'original': original_text,\n",
    "                'summary': summary_text,\n",
    "                # 'label': corrected_type,\n",
    "                'question' : question,\n",
    "                'answers' : answers\n",
    "            })\n",
    "            # id = id+1\n",
    "\n",
    "        # 각 파일 처리 후 DataFrame 생성 및 'text' 열 추가\n",
    "        type_data_df = pd.DataFrame(data_list)\n",
    "        type_data_df['context'] = '[original]' + type_data_df['original'] + '[/original][summary]' + type_data_df['summary'] + '[/summary]'\n",
    "        type_data_df.drop(columns=['original', 'summary'], inplace=True)\n",
    "\n",
    "    # 타입별 데이터프레임을 합친다\n",
    "    data_frames.append(type_data_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 병합\n",
    "data_df_validation_human_fact = pd.concat(data_frames, ignore_index=True)\n",
    "print('shape: ', data_df_validation_human_fact.shape)\n",
    "print(data_df_validation_human_fact.head())\n",
    "\n",
    "# # csv 파일 경로 설정\n",
    "csv_path = base_output_dir_path + 'validation_human_fact.csv'\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "data_df_validation_human_fact.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'데이터가 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d7307e-8a16-4685-b1da-3735bf783fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (426, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                           answers  \\\n",
      "0  {'text': ['광주/전라/제주에서'], 'answer_start': [116]}   \n",
      "1       {'text': ['도전 이며'], 'answer_start': [116]}   \n",
      "2        {'text': ['그만쓰는게'], 'answer_start': [80]}   \n",
      "3      {'text': ['정부,지자체,'], 'answer_start': [61]}   \n",
      "4         {'text': ['15년전'], 'answer_start': [84]}   \n",
      "\n",
      "                                             context  \n",
      "0  [original]01. 지방선거 지지 정당 질문 | 6월 13일 시도지사 등을 새...  \n",
      "1  [original]최악의 한 해였다. 실적은 급전 직하했고, 주가는 폭락했다. 이제...  \n",
      "2  [original]직장생활 초기에는 나이를 내세우며 아버지뻘이라고 자처하는 취재원을...  \n",
      "3  [original]일단 정부는 청년 창업 지원책으로 청년층 취업 문제와 창조경제 실...  \n",
      "4  [original]백화점과 마트자동차가전 등 각 업계가 총출동한 대한민국 동행세일이...  \n",
      "데이터가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# VL_사람요약문_의견제시형_corrected_type1 ~ VL_사람요약문_의견제시형_corrected_type6\n",
    "\n",
    "# 데이터프레임을 합칠 때 사용할 리스트\n",
    "data_frames = []\n",
    "# id = 1\n",
    "\n",
    "# 각 타입별 폴더를 반복 처리\n",
    "for type_num in range(1, 7):\n",
    "    human_type_data_path = base_dir_path + f'VL_사람요약문_의견제시형_corrected_type{type_num}'\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 가져오고, '.json' 확장자를 가진 파일만 필터링\n",
    "    json_files = [file for file in os.listdir(human_type_data_path) if file.endswith('.json')]\n",
    "\n",
    "    # 전체 파일 순회\n",
    "    for index, filename in enumerate(json_files):\n",
    "        json_path = os.path.join(human_type_data_path, filename)\n",
    "        with open(json_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            id = data['annotation']['original_summary']['human_abstractive_summary']['author']['id']\n",
    "            original_text = data['original_text']\n",
    "            corrected_type = type_num\n",
    "            summary_text = data['annotation']['original_summary']['human_abstractive_summary']['text']\n",
    "            question = error_type_question(corrected_type)\n",
    "\n",
    "            corrected_summary = data['annotation']['corrected_summary']\n",
    "            corrected_text = corrected_summary[f'corrected_type{type_num}']['errors'][0]['sub']\n",
    "            error_begin = corrected_summary[f'corrected_type{type_num}']['errors'][0]['begin']\n",
    "            answers = {'text': [corrected_text], 'answer_start': [error_begin]}\n",
    "            \n",
    "            data_list.append({\n",
    "                'id' : id,\n",
    "                'original': original_text,\n",
    "                'summary': summary_text,\n",
    "                # 'label': corrected_type,\n",
    "                'question' : question,\n",
    "                'answers' : answers\n",
    "            })\n",
    "            # id = id+1\n",
    "\n",
    "        # 각 파일 처리 후 DataFrame 생성 및 'text' 열 추가\n",
    "        type_data_df = pd.DataFrame(data_list)\n",
    "        type_data_df['context'] = '[original]' + type_data_df['original'] + '[/original][summary]' + type_data_df['summary'] + '[/summary]'\n",
    "        type_data_df.drop(columns=['original', 'summary'], inplace=True)\n",
    "\n",
    "    # 타입별 데이터프레임을 합친다\n",
    "    data_frames.append(type_data_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 병합\n",
    "data_df_validation_human_opinion = pd.concat(data_frames, ignore_index=True)\n",
    "print('shape: ', data_df_validation_human_opinion.shape)\n",
    "print(data_df_validation_human_opinion.head())\n",
    "\n",
    "# # csv 파일 경로 설정\n",
    "csv_path = base_output_dir_path + 'validation_human_opinion.csv'\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "data_df_validation_human_opinion.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'데이터가 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "831d99c7-2a0a-4008-b711-04ffe943e9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (234, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                             answers  \\\n",
      "0  {'text': ['갑과 을의 개인적 갈등이 심화되어 회사 내부 관계에까지 영향을 ...   \n",
      "1  {'text': ['도시재개발법에 따르면 도시의 발전 및 공공복리 증진에 기여한다는...   \n",
      "2  {'text': ['도시 및 주거환경정비법 제 도시 및 주거환경정비법 제84조는 형...   \n",
      "3  {'text': ['계약 체결에 관하여 신의성실의 원칙에 기한 선의가 강하게 요청되...   \n",
      "4  {'text': ['피보험자가 보험계약자에 대하여 그 보증보험계약의 주계약과 관련한...   \n",
      "\n",
      "                                             context  \n",
      "0  [original]1 산업재해보상보험법상의 업무상 재해라 함은 업무수행중 그 업무에...  \n",
      "1  [original]도시재개발법(1995. 12. 29. 법률 제5116호로 전문 개...  \n",
      "2  [original]1 도시 및 주거환경정비법 제84조는  형법 제129조 내지 제1...  \n",
      "3  [original]1 생명보험계약은 사람의 생명에 관한 우연한 사고에 대하여 금전을...  \n",
      "4  [original]1보험계약자의 채무불이행시 계약보증금채권을 담보하는 계약이행보증보...  \n",
      "데이터가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# VL_사람요약문_자유형_corrected_type1 ~ VL_사람요약문_자유형_corrected_type6\n",
    "\n",
    "# 데이터프레임을 합칠 때 사용할 리스트\n",
    "data_frames = []\n",
    "# id = 1\n",
    "\n",
    "# 각 타입별 폴더를 반복 처리\n",
    "for type_num in range(1, 7):\n",
    "    if type_num == 5 :\n",
    "        continue\n",
    "        \n",
    "    human_type_data_path = base_dir_path + f'VL_사람요약문_자유형_corrected_type{type_num}'\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 가져오고, '.json' 확장자를 가진 파일만 필터링\n",
    "    json_files = [file for file in os.listdir(human_type_data_path) if file.endswith('.json')]\n",
    "\n",
    "    # 전체 파일 순회\n",
    "    for index, filename in enumerate(json_files):\n",
    "        json_path = os.path.join(human_type_data_path, filename)\n",
    "        with open(json_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            id = data['annotation']['original_summary']['human_abstractive_summary']['author']['id']\n",
    "            original_text = data['original_text']\n",
    "            corrected_type = type_num\n",
    "            summary_text = data['annotation']['original_summary']['human_abstractive_summary']['text']\n",
    "            question = error_type_question(corrected_type)\n",
    "\n",
    "            corrected_summary = data['annotation']['corrected_summary']\n",
    "            corrected_text = corrected_summary[f'corrected_type{type_num}']['text']\n",
    "            error_begin = corrected_summary[f'corrected_type{type_num}']['errors'][0]['begin']\n",
    "            answers = {'text': [corrected_text], 'answer_start': [error_begin]}\n",
    "            \n",
    "            data_list.append({\n",
    "                'id' : id,\n",
    "                'original': original_text,\n",
    "                'summary': summary_text,\n",
    "                # 'label': corrected_type,\n",
    "                'question' : question,\n",
    "                'answers' : answers\n",
    "            })\n",
    "            # id = id+1\n",
    "\n",
    "        # 각 파일 처리 후 DataFrame 생성 및 'text' 열 추가\n",
    "        type_data_df = pd.DataFrame(data_list)\n",
    "        type_data_df['context'] = '[original]' + type_data_df['original'] + '[/original][summary]' + type_data_df['summary'] + '[/summary]'\n",
    "        type_data_df.drop(columns=['original', 'summary'], inplace=True)\n",
    "\n",
    "    # 타입별 데이터프레임을 합친다\n",
    "    data_frames.append(type_data_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 병합\n",
    "data_df_validation_human_free = pd.concat(data_frames, ignore_index=True)\n",
    "print('shape: ', data_df_validation_human_free.shape)\n",
    "print(data_df_validation_human_free.head())\n",
    "\n",
    "# # csv 파일 경로 설정\n",
    "csv_path = base_output_dir_path + 'validation_human_free.csv'\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "data_df_validation_human_free.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'데이터가 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41b3eced-fa81-40f7-a42a-a008763feb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합이 완료되었습니다.\n",
      "shape: (1114, 4)\n",
      "           id                   question  \\\n",
      "0  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "1  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "2  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "3  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "4  human-2020  한글 맞춤법, 띄어쓰기 오류가 발생한 부분은?   \n",
      "\n",
      "                                            answers  \\\n",
      "0          {'text': ['9시5분'], 'answer_start': [82]}   \n",
      "1          {'text': ['3배가량'], 'answer_start': [49]}   \n",
      "2  {'text': ['상승했고 ,증권업계는'], 'answer_start': [115]}   \n",
      "3    {'text': ['2억3000만원을'], 'answer_start': [105]}   \n",
      "4        {'text': ['순으로매년'], 'answer_start': [145]}   \n",
      "\n",
      "                                             context  \n",
      "0  [original]30일 코스닥 지수는 보합권에서 상승 출발했다. 미국 연방공개시장...  \n",
      "1  [original]경기도 노후 하수관이 1만㎞에 달하며 지하안전 주의보가 발령된(본...  \n",
      "2  [original]정부와 여당인 더불어민주당이 증권거래세 폐지를 본격 추진하면서 주...  \n",
      "3  [original]엄재천 올해 장학생 280명 선발2억3천만원 지급 계획,  22일...  \n",
      "4  [original]전북경찰이 해마다 업무 중 불의의 사고를 당하는 것으로 나타났다....  \n"
     ]
    }
   ],
   "source": [
    "# validation 사람요약문 병합\n",
    "\n",
    "csv_paths = [\n",
    "    base_output_dir_path + 'validation_human_fact.csv',\n",
    "    base_output_dir_path + 'validation_human_opinion.csv',\n",
    "    base_output_dir_path + 'validation_human_free.csv'\n",
    "]\n",
    "\n",
    "dataframes = [pd.read_csv(path, encoding='utf-8') for path in csv_paths]\n",
    "merged_validation_human_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 결과 DataFrame을 새로운 CSV 파일로 저장\n",
    "output_path = base_output_dir_path + 'training_human_data.csv'\n",
    "merged_validation_human_dataframe.to_csv(output_path, index=False)\n",
    "\n",
    "print('병합이 완료되었습니다.')\n",
    "print('shape:', merged_validation_human_dataframe.shape)\n",
    "print(merged_validation_human_dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2f6252-27cc-456d-a518-305950dc0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "data = pd.read_csv('./data/training/training_human_data.csv')\n",
    "\n",
    "# 데이터프레임을 레이블별로 분리\n",
    "groups = data.groupby('question')\n",
    "\n",
    "# 각 레이블에서 10%를 테스트 데이터로 추출\n",
    "test_data_list = []\n",
    "train_data_list = []\n",
    "\n",
    "for label, group in groups:\n",
    "    train, test = train_test_split(group, test_size=0.1, random_state=42, stratify=group['question'])\n",
    "    test_data_list.append(test)\n",
    "    train_data_list.append(train)\n",
    "\n",
    "# 테스트 데이터와 훈련 데이터 합치기\n",
    "test_data = pd.concat(test_data_list)\n",
    "train_data = pd.concat(train_data_list)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "train_data.to_csv('./data/training/training_human_data_2.csv', index=False)\n",
    "test_data.to_csv('./data/test/test_human_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c113f3-8842-486c-804d-7241cbd86be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
